# nbiot_detector_core

## ğŸ“• Table Of Contents

<!--ts-->

- [ğŸŒŸ System Architecture](#-system-architecture)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ”Œ Exposing Services](#-exposing-services)
- [ğŸ”§ Addtional Setup](#-additional-setup)
- [ğŸ§¹ Cleanup](#-cleanup)

## ğŸŒŸ System Architecture
<p align="center">
<img src="./images/cloudflare-approach-architecture.png" width=100% height=100%>

<p align="center">
    System Architecture
</p>

## ğŸ“ Repository Structure
```bash
./nbiot_detector_core/
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ README.md
â”œâ”€â”€ app
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ model_definition.py
â”‚Â Â  â”œâ”€â”€ requirements.txt
â”‚Â Â  â””â”€â”€ saved_assets
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ document
â”œâ”€â”€ example.csv
â”œâ”€â”€ images
â”œâ”€â”€ kubernetes
â”‚Â Â  â”œâ”€â”€ Dockerfile.jenkins
â”‚Â Â  â”œâ”€â”€ Dockerfile.jenkins-agent
â”‚Â Â  â”œâ”€â”€ base
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ argocd
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ elasticsearch.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ filebeat.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jaeger.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jenkins.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ kibana.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ nbiot-detector.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cloudflare-ingress.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cluster-issuer.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ google-ingress.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ingress.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jenkins-01-volume.yaml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jenkins-rbac-ssh.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ jenkins-sa-rbac.yaml
â”‚Â Â  â””â”€â”€ helm
â”‚Â Â      â”œâ”€â”€ app-nbiot-detector
â”‚Â Â      â”œâ”€â”€ argo-cd
â”‚Â Â      â”œâ”€â”€ cert-manager
â”‚Â Â      â”œâ”€â”€ cloudflare-tunnel-remote
â”‚Â Â      â”œâ”€â”€ elasticsearch
â”‚Â Â      â”œâ”€â”€ filebeat
â”‚Â Â      â”œâ”€â”€ ingress-nginx
â”‚Â Â      â”œâ”€â”€ jaeger-all-in-one
â”‚Â Â      â”œâ”€â”€ jenkins
â”‚Â Â      â”œâ”€â”€ kibana
â”‚Â Â      â””â”€â”€ kube-prometheus-stack
â”œâ”€â”€ local
â”‚Â Â  â”œâ”€â”€ alertmanager
â”‚Â Â  â”œâ”€â”€ elk
â”‚Â Â  â”œâ”€â”€ grafana
â”‚Â Â  â””â”€â”€ prometheus
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ lightgbm.ipynb
â”‚Â Â  â””â”€â”€ main.ipynb
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ scripts
â”‚Â Â  â”œâ”€â”€ bootstrap.sh
â”‚Â Â  â”œâ”€â”€ cleanup.sh
â”‚Â Â  â”œâ”€â”€ grant-permission-for-certmanager.sh
â”‚Â Â  â””â”€â”€ manual-delete-kibana.sh
â”œâ”€â”€ terraform
â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”œâ”€â”€ outputs.tf
â”‚Â Â  â”œâ”€â”€ prod.tfvars
â”‚Â Â  â””â”€â”€ variables.tf
â””â”€â”€ tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ deleted.test_main.py
    â”œâ”€â”€ test_main_endpoints.py
    â”œâ”€â”€ test_predict_batch.py
    â””â”€â”€ test_predict_single.py
```

## ğŸš€ Quick start

### 1. Prerequisites ğŸ”§

Before you begin, ensure you have the following command-line tools installed and configured:
* **`git`**: To clone the repository.
* **`kubectl`**: To interact with the Kubernetes cluster.
* **`helm`**: To manage Kubernetes packages (version 3+).
* **`docker`**: To containerize the application (version 25+).
* **`gcloud`** (For Production): To authenticate with Google Cloud. Ensure you've authenticated by running `gcloud auth login` and `gcloud auth application-default login`.
* **`terraform`** (For Production): To provision the cloud infrastructure.
* **`minikube`** (For Local): To run a local Kubernetes cluster.

### 2. Initial Setup

First, clone the repository to your local machine.

```bash
git clone <repository-url>
cd nbiot_detector_core/
```

### 3. Deployment Instructions

The `bootstrap.sh` script handles both production and local deployments. You must run it from the `scripts/` directory.

### Production Deployment (GKE)

This process will provision a new GKE cluster and deploy all the services.

**Step 1: Configure Terraform Variables**
Before running the script, you must configure your Google Cloud settings. Edit the Terraform variables file:

**File to Edit:** `terraform/prod.tfvars`

Update the file with your specific GCP `project_id` and desired `region`
```terraform
# terraform/prod.tfvars

project_id          = "your-gcp-project-id"
region              = "asia-southeast1"
deletion_protection = false
node_count          = 3
machine_type        = "e2-standard-2"
```

**Step 2: Run the Bootstrap Script**

Login to GCP with CLI
```shell
gcloud auth application-default login
```

Navigate to the `scripts` directory and execute the bootstrap script with the `prod` argument.

```bash
cd scripts/
bash bootstrap.sh prod
```

The script will now perform the following actions:
1.  **Initialize Terraform** and apply the configuration to create the GKE cluster.
2.  **Configure `kubectl`** to connect to your new GKE cluster.
3.  **Create Kubernetes namespaces** for all components (`monitoring`, `logging`, `jenkins`, etc.).
4.  **Deploy Helm charts** for Nginx, Prometheus (`kube-prometheus-stack`), ArgoCD, and the Cloudflare Tunnel.
5.  **Apply base Kubernetes manifests**, including persistent volumes for Jenkins.
6.  **Apply ArgoCD application manifests** to manage the core services.
    * **Note:** The script includes a **6-minute pause** after deploying Elasticsearch to allow it to initialize properly before other components that depend on it are created.

#### Local Deployment (Minikube)
This process uses Minikube to create a local Kubernetes cluster for testing. Navigate to the `scripts` directory and run the script with the `local` argument.
```bash
cd scripts/
bash bootstrap.sh local
```
The script will:
1.  **Start Minikube**.
2.  Perform the same namespace, Helm chart, and manifest deployments as the production environment, but within your local Minikube cluster.


## ğŸ”Œ Exposing Services
After the `bootstrap.sh` script completes,  you need to expose the services to access them. The following methods apply to the **Production (GKE) Deployment**.

### [Option 1: Ingress without SSL (Using nip.io)](./document/Option1.md)


### [Option 2: Ingress with Google Cloud DNS and Let's Encrypt SSL](./document/Option2.md)
This method provides a secure setup using your own domain managed by Google Cloud DNS.


### [Option 3: Ingress with Cloudflare Tunnel (Recommended)](./document/Option3.md)
This method simplifies the architecture and enhances security by using a Cloudflare Tunnel. No ports need to be opened on your firewall.

## ğŸ”§ Additional Setup

### Jenkins setup

***Notice:*** I will assume that you have a docker hub account and have your own docker's repositories

**Step 1:** Create docker access token
1. **Login to Docker Hub**
2. `Account settings` > `Personal access tokens` > `Generate new token` (with Read & Write scope)
<img src="./images/create-docker-access-token.png" width=100% height=100%>
3. **Keep your token handy**

**Step 2:** Create github webhook
1. Go to the GitHub repository and click on `Settings`
2. Click on `Webhooks` and then select `Add Webhook`
3. Enter URL of your Jenkins server (https://jenkins.tuan-lnm.cloud/multibranch-webhook-trigger/invoke?token=demo-token)
<img src="./images/create-github-webhook.png" width=100% height=100%>
3.1. Note that you can use any token's name that you want, mine was `demo-token` <br>
3.2 For deployment with option 1, please choose SSL verfication disable

4. Webhook's status should be `green`
<img src="./images/webhook-status.png" width=100% height=100%>

**Step 3**: Setup github access token
1. Create your own ssh key
```bash
ssh-keygen -t rsa -b 4096 -C "jenkins@k8s" -f id_rsa_jenkins -N ""
```

2. Go to the GitHub repository and click on `Settings`
3. Click on `Deploy keys` and then Select `Add Deploy key`
4. Paste in your public key `id_rsa_jenkins.pub`
5. Create github-ssh-key secret
```bash
kubectl create secret generic github-ssh-key --namespace=jenkins --type=kubernetes.io/ssh-auth
--from-file=ssh-privatekey=./id_rsa_jenkins
```

**Step 4**: Setup CI Pipeline
1. Go to `Jenkins` dashboard and click on `New Item`
2. Name your project (eg. `nbiot-detector`) and select `Multibranch Pipeline`
3. Click on `Branch Sources` and then click on `Add Source`. Select `GitHub` and click on `Add`. Enter the URL of your GitHub repository.
4. At `Scan Multibranch Pipeline Triggers`, choose `Scan by webhook`. Enter `demo-token` (or your token name at step 2).
5. At `Registry credentials`, click on `Add` > `Jenkins`. Enter your Username, Password (Docker access token) and ID=`docker-jenkins`.
6. Click `Save`. Your pipeline should be green
<img src="./images/setup-ci.png" width=100% height=100%>


## ğŸ§¹ Cleanup
To tear down all deployed resources, use the `cleanup.sh` script from the `scripts/` directory.

### Production Cleanup
This will destroy the GKE cluster and all other resources created by Terraform.
```bash
cd scripts/
bash cleanup.sh prod
```
### Local Cleanup
This will delete the Minikube cluster.
```bash
cd scripts/
bash cleanup.sh local
```